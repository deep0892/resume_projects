{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Competition** - Given a set of images of Cassava leaves we need to classify them as one of the four diseases or healthy.\n",
    "* **Data** - A collection of 21397 labelled images\n",
    "* **Evaluation** - Classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take a quick look at the data files and train our model in this notebook. The model can be saved and used for inference in a later notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "ROOT_DIR = '../input/cassava-leaf-disease-classification/'\n",
    "os.listdir(ROOT_DIR)\n",
    "\n",
    "import json # to read in the 'label_num_to_disease_map.json' file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import EfficientNetB0, EfficientNetB1\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = '../input/cassava-leaf-disease-classification/train_images/'\n",
    "TEST_DIR = '../input/cassava-leaf-disease-classification/test_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "def seed_everything(seed = 42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "seed_everything(seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(ROOT_DIR + 'train.csv')\n",
    "sample_df = pd.read_csv(ROOT_DIR + 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape, sample_df.shape)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(ROOT_DIR + 'label_num_to_disease_map.json')\n",
    "data = json.load(f)\n",
    "print(json.dumps(data, indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = train_df.sample(20)\n",
    "display(z)\n",
    "images, labels = z['image_id'].tolist(), z['label'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting 20 randomly sampled images with class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,20))\n",
    "for i in range(20):\n",
    "    plt.subplot(4,5,i+1)\n",
    "    img = cv2.imread(TRAIN_DIR + images[i])\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.title(data[str(labels[i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting a count plot and pie chart for class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x = 'label', data = train_df, palette = 'Pastel1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_df = train_df['label'].value_counts().reset_index()\n",
    "pie_df.columns = ['label', 'count']\n",
    "fig = px.pie(pie_df, values = 'count', names = 'label', color_discrete_sequence = px.colors.qualitative.Pastel)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a class imbalance problem here. The Cassava Mosaic Disease (CMD) samples are more compared to other classes. We can solve this by either upsampling other class samples or downsampling the CMD samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset for training and validation\n",
    "Reserving 20% of data for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.astype({\"label\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(train_df, test_size = 0.2, random_state = 42)\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating ImageDataGenerator to generate data in batches and perform image augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "size = (IMG_SIZE,IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "                    rotation_range = 40,\n",
    "                    width_shift_range = 0.2,\n",
    "                    height_shift_range = 0.2,\n",
    "                    shear_range = 0.2,\n",
    "                    zoom_range = 0.2,\n",
    "                    horizontal_flip = True,\n",
    "                    vertical_flip = True,\n",
    "                    fill_mode = 'nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "                    train,\n",
    "                    directory = TRAIN_DIR,\n",
    "                    x_col = \"image_id\",\n",
    "                    y_col = \"label\",\n",
    "                    target_size = size,\n",
    "                    class_mode = \"sparse\",\n",
    "                    batch_size = 64,\n",
    "                    shuffle = True,\n",
    "                    seed = 42,\n",
    "                    interpolation = \"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_generator = datagen.flow_from_dataframe(\n",
    "                    test,\n",
    "                    directory = TRAIN_DIR,\n",
    "                    x_col = \"image_id\",\n",
    "                    y_col = \"label\",\n",
    "                    target_size = size,\n",
    "                    class_mode = \"sparse\",\n",
    "                    batch_size = 64,\n",
    "                    shuffle = False,\n",
    "                    seed = 42,\n",
    "                    interpolation = \"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    # initialize EfficientNetB0 model with input shape as (224,224,3)\n",
    "    model.add(EfficientNetB0(input_shape = (IMG_SIZE, IMG_SIZE, 3), include_top = False, weights = 'imagenet'))\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation = 'relu'))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Dense(NUM_CLASSES, activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "             optimizer = Adam(learning_rate = 0.001),\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop training when the validation loss metric has stopped decreasing for 5 epochs.\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss',\n",
    "                               patience = 5,\n",
    "                               mode = 'min',\n",
    "                               restore_best_weights = True)\n",
    "\n",
    "# Save the model with the minimum validation loss\n",
    "checkpoint = ModelCheckpoint('best_model.hdf5', \n",
    "                             monitor = 'val_loss',\n",
    "                             verbose = 1,\n",
    "                             mode = 'min', \n",
    "                             save_best_only = True)\n",
    "# reduce learning rate\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                              factor = 0.2,\n",
    "                              patience = 3,\n",
    "                              min_lr = 0.001,\n",
    "                              mode = 'min',\n",
    "                              verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    validation_data = valid_generator,\n",
    "                    epochs = EPOCHS,\n",
    "                    steps_per_epoch = STEP_SIZE_TRAIN,\n",
    "                    validation_steps = STEP_SIZE_VALID,\n",
    "                    callbacks = [early_stopping, checkpoint, reduce_lr]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_generator(generator = valid_generator, steps = STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'c-', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'y-', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'c-', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'y-', label='Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction and submission notebook can be found here : [Inference Notebook](https://www.kaggle.com/lavanyask/cassava-leaf-disease-inference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
